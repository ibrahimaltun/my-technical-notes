### conf dosyasini tam aktif etmek icin

$ **pkill -f 'org.apache.spark.deploy.worker.Worker'**
$ **SPARK_HOME/sbin/stop-all.sh**
$ **SPARK_HOME/sbin/start-all.sh**

### Modlar

| Mod                 | AÃ§Ä±klama                                                                          |
| ------------------- | --------------------------------------------------------------------------------- |
| **Local Mode**      | Tek makinede, tek JVM iÃ§inde Ã§alÄ±ÅŸÄ±r. KÃ¼Ã§Ã¼k testler iÃ§in uygundur.                |
| **Standalone Mode** | Spark kendi baÅŸÄ±na bir cluster yÃ¶netir. Master + Worker mimarisi vardÄ±r.          |
| **Cluster Mode**    | Spark, YARN, Mesos veya Kubernetes gibi harici bir cluster yÃ¶neticisiyle Ã§alÄ±ÅŸÄ±r. |


### âš™ï¸ Spark KonfigÃ¼rasyonlarÄ±: DetaylÄ± AÃ§Ä±klamalar

### ğŸ”¥ Bellek ve CPU AyarlarÄ±

|Ayar|AÃ§Ä±klama|
|---|---|
|`spark.executor.memory`|Her executor iÃ§in ayrÄ±lacak RAM miktarÄ±. Ã–rnek: `"8g"` â†’ 8 GB.|
|`spark.driver.memory`|Driver iÃ§in ayrÄ±lacak RAM miktarÄ±. Driver, Spark uygulamasÄ±nÄ± yÃ¶neten ana sÃ¼reÃ§tir.|
|`spark.executor.cores`|Her executor iÃ§in kullanÄ±lacak CPU Ã§ekirdeÄŸi sayÄ±sÄ±. Daha fazla Ã§ekirdek, daha fazla paralel gÃ¶rev demektir.|
|`spark.executor.instances`|Toplam kaÃ§ executor oluÅŸturulacaÄŸÄ±nÄ± belirler. Ã–rneÄŸin 4 executor Ã— 8 core = 32 paralel gÃ¶rev.|

### ğŸš€ Performans ve Shuffle AyarlarÄ±

|Ayar|AÃ§Ä±klama|
|---|---|
|`spark.sql.shuffle.partitions`|`groupBy`, `join` gibi iÅŸlemlerde veri nasÄ±l bÃ¶lÃ¼necek. VarsayÄ±lan 200â€™dÃ¼r. BÃ¼yÃ¼k veri iÃ§in 500+ Ã¶nerilir.|
|`spark.sql.autoBroadcastJoinThreshold`|KÃ¼Ã§Ã¼k tablolarÄ±n otomatik olarak broadcast edilmesini saÄŸlar. VarsayÄ±lan 10 MB. BÃ¼yÃ¼kse artÄ±rÄ±labilir.|
|`spark.default.parallelism`|RDD iÅŸlemlerinde kullanÄ±lacak varsayÄ±lan partition sayÄ±sÄ±. Genellikle executor core sayÄ±sÄ±na eÅŸitlenir.|

### ğŸ§  Uygulama ve Cluster AyarlarÄ±

|Ayar|AÃ§Ä±klama|
|---|---|
|`spark.master`|Sparkâ€™Ä±n hangi modda Ã§alÄ±ÅŸacaÄŸÄ±nÄ± belirtir. Ã–rnek: `'local[*]'`, `'spark://host:port'`, `'yarn'`.|
|`spark.app.name`|UygulamanÄ±n adÄ±. Spark UIâ€™da gÃ¶rÃ¼nÃ¼r.|
|`spark.submit.deployMode`|`'client'` veya `'cluster'`. Cluster modunda driver bir worker nodeâ€™da Ã§alÄ±ÅŸÄ±r.|

### ğŸ§¹ Temizlik ve Bellek YÃ¶netimi

|Ayar|AÃ§Ä±klama|
|---|---|
|`spark.storage.memoryFraction`|BelleÄŸin ne kadarÄ±nÄ±n cache iÃ§in ayrÄ±lacaÄŸÄ±nÄ± belirler. (Spark 2.xâ€™ten sonra deprecated oldu.)|
|`spark.memory.fraction`|Toplam belleÄŸin ne kadarÄ±nÄ±n execution ve storage iÃ§in kullanÄ±lacaÄŸÄ±nÄ± belirler.|
|`spark.memory.storageFraction`|BelleÄŸin ne kadarÄ±nÄ±n sadece storage (cache/persist) iÃ§in ayrÄ±lacaÄŸÄ±nÄ± belirler.|

### ğŸ“¦ Dosya ve I/O AyarlarÄ±

|Ayar|AÃ§Ä±klama|
|---|---|
|`spark.sql.files.maxPartitionBytes`|Okunan dosyalarÄ±n partition boyutunu belirler. KÃ¼Ã§Ã¼kse daha fazla paralellik.|
|`spark.sql.files.openCostInBytes`|Dosya aÃ§ma maliyeti. Partition sayÄ±sÄ±nÄ± etkiler.|
|`spark.sql.parquet.filterPushdown`|Parquet dosyalarÄ±nda filtreleme iÅŸlemini hÄ±zlandÄ±rÄ±r. Genellikle `true` olmalÄ±.|

### ğŸ§ª GeliÅŸmiÅŸ Ayarlar

| Ayar                              | AÃ§Ä±klama                                                                               |
| --------------------------------- | -------------------------------------------------------------------------------------- |
| `spark.speculation`               | GÃ¶revler yavaÅŸsa aynÄ± iÅŸi baÅŸka executorâ€™da tekrar baÅŸlatÄ±r. YÃ¼ksek gecikmeyi azaltÄ±r. |
| `spark.dynamicAllocation.enabled` | Executor sayÄ±sÄ±nÄ± otomatik olarak artÄ±rÄ±p azaltÄ±r. KaynaklarÄ± daha verimli kullanÄ±r.   |
| `spark.local.dir`                 | GeÃ§ici dosyalarÄ±n yazÄ±lacaÄŸÄ± dizin. SSD olan bir dizin seÃ§ilirse performans artar.     |




 